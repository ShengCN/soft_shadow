{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data_process.shadow_render import render_shadow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from ssn import ssn_dataset\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "from utils.net_utils import show_batch, show_light_batch\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing relative vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ibls(rotating around)\n",
    "def to_mask(img):\n",
    "    img = (img[:,:,0] + img[:,:,1] + img[:,:,2])/3.0\n",
    "    img = img/np.max(img)\n",
    "    return img\n",
    "\n",
    "# relative_vec = np.array([0.108, 2.64, 1.8])\n",
    "# ibl_img = to_mask(render_shadow(relative_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from ssn.ssn_dataset import Mask_Transform, IBL_Transform, ToTensor\n",
    "import os \n",
    "import random\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from valid_relight_ssn import predict, compute_ibl, merge_result\n",
    "from skimage.transform import resize\n",
    "\n",
    "def show_np(img, cmap='gray', title=''):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.title(title)\n",
    "    plt.imshow(np.squeeze(img), cmap=cmap)\n",
    "    \n",
    "def to_one_batch(img_tensor):\n",
    "    c,h,w = img_tensor.size()\n",
    "    return img_tensor.view(1,c,h,w)\n",
    "\n",
    "def to_numpy(one_batch):\n",
    "    return one_batch[0].detach().cpu().numpy().transpose((1,2,0))\n",
    "\n",
    "def png_to_3channel(img):\n",
    "    \"\"\" mask image from 4 channel png to 3 channel\"\"\"\n",
    "    h,w,c = img.shape\n",
    "    if c != 4:\n",
    "        print(\"image is not 4 channel\")\n",
    "        return img\n",
    "    \n",
    "    out_img, alpha = img[:,:,0:3]/255.0, img[:,:,3]/255.0\n",
    "    out_img[:,:,0] = out_img[:,:,0] * alpha\n",
    "    out_img[:,:,1] = out_img[:,:,1] * alpha\n",
    "    out_img[:,:,2] = out_img[:,:,2] * alpha\n",
    "    out_img = out_img * 255.9\n",
    "    out_img = out_img.astype(np.uint8)\n",
    "    return out_img\n",
    "\n",
    "def padding_image(img, padding_size):\n",
    "    \"\"\" padding an image with a padding size \"\"\"\n",
    "    if padding_size == 0:\n",
    "        return img\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    if len(img.shape) == 2:\n",
    "        c = 1\n",
    "    else:\n",
    "        c = img.shape[-1]\n",
    "    \n",
    "    img = img.reshape((h,w,c))\n",
    "    out_img = np.zeros((h + 2 * padding_size, w + 2 * padding_size, c),dtype=np.float64)\n",
    "    out_img[padding_size:padding_size + h, padding_size:padding_size+w, 0:c] = img[:,:,0:c]\n",
    "    return out_img\n",
    "\n",
    "def real_to_mask(img, unpadded_size=80):\n",
    "    mask = img[:,:,-1]\n",
    "    img = png_to_3channel(img)\n",
    "    \n",
    "    resize_w = unpadded_size\n",
    "    img = resize(img, (resize_w, resize_w))\n",
    "    img = padding_image(np.array(img), (256 - resize_w)//2)\n",
    "    mask = resize(mask, (resize_w,resize_w))\n",
    "    mask = padding_image(mask, (256 - resize_w)//2)\n",
    "    \n",
    "    thresh_hold = 0.3\n",
    "    mask[np.where(mask < thresh_hold)] = 0.0\n",
    "    mask[np.where(mask >= thresh_hold)] = 1.0\n",
    "    \n",
    "    mask = np.squeeze((mask * 255.9).astype(np.uint8))\n",
    "    mask = np.array([mask,] * 3).transpose((1,2,0))\n",
    "    \n",
    "    return img, mask\n",
    "\n",
    "def synthetic_to_mask(img):\n",
    "    img = img[:,:,0:3]\n",
    "    img = resize(img, (256,256))\n",
    "\n",
    "    h,w,c = img.shape\n",
    "    mask = np.zeros((h,w,3), dtype=np.uint8)\n",
    "    mask[np.where(img != 0)] = 255\n",
    "    return img, mask\n",
    "\n",
    "testing_fname = '/home/ysheng/Dataset/soft_shadow/real_human_testing_set/10944340-young-man-standing.png'\n",
    "testing_img = Image.open(testing_fname)\n",
    "testing_img, testing_mask_img = real_to_mask(np.array(testing_img))\n",
    "show_np(testing_img)\n",
    "show_np(testing_mask_img)\n",
    "\n",
    "print(testing_img.dtype)\n",
    "print(testing_mask_img.dtype)\n",
    "print(testing_mask_img[np.where(testing_mask_img!=0)])\n",
    "print(np.max(testing_mask_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_real_result(test_fname, mask_size,testing_ibl):\n",
    "    testing_img = np.array(Image.open(test_fname))\n",
    "    testing_img, testing_mask = real_to_mask(np.array(testing_img), mask_size)\n",
    "\n",
    "    print(np.max(testing_img))\n",
    "    print(np.max(testing_mask))\n",
    "    print(testing_mask.shape)\n",
    "\n",
    "    shadow = predict(testing_mask, testing_ibl)\n",
    "    print('shadow shape:{} min: {}, max: {}'.format(shadow.shape,np.min(shadow),np.max(shadow)))\n",
    "    shadow = np.clip(shadow, 0.0, 1.0)\n",
    "\n",
    "    shadow_result = merge_result(testing_img, testing_mask, shadow)\n",
    "\n",
    "    show_np(shadow_result, title='mask size: {}'.format(mask_size))\n",
    "    plt.savefig('{}.png'.format(mask_size))\n",
    "    show_np(testing_img)\n",
    "    show_np(testing_mask)\n",
    "    show_np(np.squeeze(testing_ibl))\n",
    "    show_np(np.squeeze(shadow), 'gray')\n",
    "\n",
    "testing_fname = '/home/ysheng/Dataset/soft_shadow/real_human_testing_set/10944340-young-man-standing.png'\n",
    "testing_ibl = compute_ibl(0, 160)\n",
    "\n",
    "h,w = testing_ibl.shape\n",
    "input_ibl = np.zeros((h,w,1), dtype=testing_ibl.dtype)\n",
    "input_ibl[:,:,0] += np.squeeze(compute_ibl(0, 160)) \n",
    "input_ibl[:,:,0] += np.squeeze(compute_ibl(200, 160))\n",
    "input_ibl[:,:,0] += np.squeeze(compute_ibl(350, 160))\n",
    "\n",
    "\n",
    "predict_real_result(testing_fname, 30,input_ibl)\n",
    "predict_real_result(testing_fname, 60,input_ibl)\n",
    "predict_real_result(testing_fname, 90,input_ibl)\n",
    "predict_real_result(testing_fname, 120,input_ibl)\n",
    "predict_real_result(testing_fname, 150,input_ibl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make animations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from animation import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "animator = bigger_gaussian_ibl_animator(size=50)\n",
    "\n",
    "total = 1000\n",
    "for i in tqdm(range(total)):\n",
    "    if i <=10 or i >=12:\n",
    "        continue\n",
    "    else:\n",
    "        # ibl = animator.animate_ibl(i, total)\n",
    "        # show_np(ibl)\n",
    "        print(animator.get_ibl_num())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valid_relight_ssn import render_animation\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from animation import *\n",
    "\n",
    "def delete_old_imgs(folder):\n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    files = glob.glob(folder + \"/*.*\")\n",
    "    for f in files:\n",
    "        if os.path.isfile(f):\n",
    "            os.remove(f)\n",
    "\n",
    "def animate_real_data(file_path, out_folder, animator, prefix_name):\n",
    "    testing_img = Image.open(file_path)\n",
    "    testing_img, testing_mask = real_to_mask(np.array(testing_img))\n",
    "\n",
    "    show_np(testing_img)\n",
    "    show_np(testing_mask)\n",
    "    \n",
    "    print(testing_img.shape)\n",
    "    print(testing_mask.shape)\n",
    "    print('mask max: {}'.format(np.max(testing_mask)))\n",
    "    \n",
    "    render_animation(testing_img, testing_mask, out_folder, animator, prefix_name)\n",
    "\n",
    "def animate_syn_data(file_path, out_folder, animator, prefix_name):\n",
    "    testing_img = np.array(Image.open(file_path))\n",
    "\n",
    "    testing_img, testing_mask = synthetic_to_mask(testing_img)\n",
    "    testing_img = (255-testing_mask)/255.0\n",
    "    print(testing_img.shape)\n",
    "    print(testing_mask.shape)\n",
    "    print('mask max: {}'.format(np.max(testing_mask)))\n",
    "    show_np(testing_img)\n",
    "    show_np(testing_mask)\n",
    "    \n",
    "    render_animation(testing_img, testing_mask, out_folder, animator, prefix_name)\n",
    "    \n",
    "# animator_list = [three_ibl_animator(), bigger_gaussian_ibl_animator()]\n",
    "# prefix_name_list = ['three_ibl', 'bigger_gaussian']\n",
    "\n",
    "animator_list = [bigger_gaussian_ibl_animator(i) for i in range(3,50,2)]\n",
    "prefix_name_list = ['bigger_radius{}'.format(i) for i in range(3,12)]\n",
    "iter_list = zip(animator_list, prefix_name_list)\n",
    "\n",
    "testing_fname = '/home/ysheng/Dataset/soft_shadow/real_human_testing_set/10944340-young-man-standing.png'\n",
    "output_folder = 'results/animations/experiments'\n",
    "\n",
    "training_human = '/home/ysheng/Dataset/soft_shadow/train/simulated_combine_female_long_fullbody_bridget8_wildwind_ssradclosedrobe_Base_Pose_Standing_A/imgs/0000000_mask.png'\n",
    "human_folder = 'results/animations/training_human_own_light'\n",
    "\n",
    "training_bottle = '/home/ysheng/Dataset/soft_shadow/train/bottle_0052_normalize/imgs/0000000_mask.png'\n",
    "bottle_folder = 'results/animations/training_simple_obj'\n",
    "    \n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(human_folder, exist_ok=True)\n",
    "os.makedirs(bottle_folder, exist_ok=True)\n",
    "\n",
    "delete_old_imgs(output_folder)\n",
    "delete_old_imgs(human_folder)\n",
    "delete_old_imgs(bottle_folder)\n",
    "    \n",
    "for animator, prefix_name in iter_list:\n",
    "    animate_real_data(testing_fname, output_folder, animator, prefix_name)\n",
    "    animate_syn_data(training_human, human_folder, animator, prefix_name)\n",
    "    animate_syn_data(training_bottle, bottle_folder, animator, prefix_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valid_relight_ssn import compute_ibl, predict\n",
    "    \n",
    "training_human = '/home/ysheng/Dataset/soft_shadow/train/simulated_combine_female_long_fullbody_bridget8_wildwind_ssradclosedrobe_Base_Pose_Standing_A/imgs/0000000_mask.png'\n",
    "ibl = compute_ibl(0, 160)\n",
    "ibl += compute_ibl(512//3, 160)\n",
    "ibl += compute_ibl(512//3 * 2, 160)\n",
    "\n",
    "show_np(ibl)\n",
    "testing_img = np.array(Image.open(training_human))\n",
    "testing_img, testing_mask = synthetic_to_mask(testing_img)\n",
    "testing_img = (255-testing_mask)/255.0\n",
    "show_np(testing_img)\n",
    "show_np(testing_mask)\n",
    "\n",
    "predicted = predict(testing_mask, ibl)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(pre)\n",
    "\n",
    "# animate_syn_data(training_human, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predicted/3.0\n",
    "print('min: {}, max: {}'.format(np.min(predicted), np.max(predicted)))\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(predicted), cmap='gray', )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted.shape)\n",
    "h,w,c = predicted.shape\n",
    "out = np.zeros((h,w,3), dtype=predicted.dtype)\n",
    "out[:,:,0] = np.squeeze(predicted)\n",
    "\n",
    "show_np(out)\n",
    "\n",
    "print('input: {} '.format(out.shape))\n",
    "\n",
    "out = np.transpose(out,(2,0,1))\n",
    "print('after transpose: {} '.format(out.shape))\n",
    "\n",
    "np.random.shuffle(out)\n",
    "print('after shuffling: {} '.format(out.shape))\n",
    "\n",
    "out = np.transpose(out, (1,2,0))\n",
    "print('after transpose: {} '.format(out.shape))\n",
    "\n",
    "show_np(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

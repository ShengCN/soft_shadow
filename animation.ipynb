{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data_process.shadow_render import render_shadow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from ssn import ssn_dataset\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "from utils.net_utils import show_batch, show_light_batch\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing relative vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate ibls(rotating around)\n",
    "def to_mask(img):\n",
    "    img = (img[:,:,0] + img[:,:,1] + img[:,:,2])/3.0\n",
    "    img = img/np.max(img)\n",
    "    return img\n",
    "\n",
    "# relative_vec = np.array([0.108, 2.64, 1.8])\n",
    "# ibl_img = to_mask(render_shadow(relative_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate 256 x 512 ibls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '/home/ysheng/Documents/adobe_shadow_net/testing_lights/'\n",
    "import os\n",
    "\n",
    "os.makedirs(output_folder,exist_ok=True)\n",
    "h,w = 16, 32\n",
    "counter = 0\n",
    "step_size_h, step_size_w = 256/16,512/32\n",
    "\n",
    "for i in range(h):\n",
    "    for j in range(w):\n",
    "        fname = '{:07d}.png'.format(counter)\n",
    "        img = np.zeros((256,512))\n",
    "        x,y = int(i * step_size_h), int(j * step_size_w)\n",
    "        img[x,y] = 1.0\n",
    "        plt.imsave(os.path.join(output_folder, fname), img)\n",
    "        counter += 1\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valid_relight_ssn import predict\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from ssn.ssn_dataset import Mask_Transform, IBL_Transform, ToTensor\n",
    "import os \n",
    "def show_np(img):\n",
    "    plt.figure()\n",
    "    plt.imshow(img)\n",
    "\n",
    "def to_one_batch(img_tensor):\n",
    "    c,h,w = img_tensor.size()\n",
    "    return img_tensor.view(1,c,h,w)\n",
    "\n",
    "def to_numpy(one_batch):\n",
    "    return one_batch[0].detach().cpu().numpy().transpose((1,2,0))\n",
    "\n",
    "def real_to_mask(img):\n",
    "    # print(np.max(img))\n",
    "    h,w,c = img.shape\n",
    "    mask = np.zeros((h,w,3), dtype=np.uint8)\n",
    "    mask[:,:,0],mask[:,:,1],mask[:,:,2]  = img[:,:,3], img[:,:,3], img[:,:,3]\n",
    "    \n",
    "    # print(np.max(mask))\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/864 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 1. Got 1024 and 1 in dimension 0 at /opt/conda/conda-bld/pytorch_1573049306803/work/aten/src/THC/generic/THCTensorMath.cu:71",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9788a0b0192c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mibl_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mibl_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mshadow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mibl_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mibl_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mibl_img\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mibl_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/adobe_shadow_net/valid_relight_ssn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(img, ibl_img)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mI_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mL_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mibl_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mpredicted_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_src_light\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0mpredicted_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mpredicted_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/adobe_shadow_net/ssn/ssn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, tl)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mout_light\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_bottleneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx11\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 6 x 16 x 16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;31m# sy = self.up_stream(out_light, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/adobe_shadow_net/ssn/ssn_submodule.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, l, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# import pdb; pdb.set_trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 768 x 16 x 16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;31m# print(y.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 1024 and 1 in dimension 0 at /opt/conda/conda-bld/pytorch_1573049306803/work/aten/src/THC/generic/THCTensorMath.cu:71"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "output_folder = '/home/ysheng/Documents/adobe_shadow_net/testing_lights/'\n",
    "output_folder = '/home/ysheng/Dataset/soft_shadow/train/airplane_0330_normalize/imgs'\n",
    "\n",
    "prediction_result_folder = '/home/ysheng/Documents/adobe_shadow_net/results/animations/'\n",
    "\n",
    "testing_fname = '/home/ysheng/Dataset/soft_shadow/real_human_testing_set/10944340-young-man-standing.png'\n",
    "testing_img = Image.open(testing_fname)\n",
    "testing_img = real_to_mask(np.array(testing_img))\n",
    "\n",
    "testing_ibl_fnames = [f for f in os.listdir(output_folder) if f.find(\"light\") != -1]\n",
    "print(len(testing_ibl_fnames))\n",
    "\n",
    "counter = 1\n",
    "\n",
    "img_trnsf = transforms.Compose([\n",
    "    Mask_Transform(),\n",
    "    ToTensor()\n",
    "])\n",
    "ibl_trnsf = transforms.Compose([\n",
    "    IBL_Transform(),\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "random.shuffle(testing_ibl_fnames) \n",
    "counter = 0\n",
    "\n",
    "for ibl_file in tqdm(testing_ibl_fnames):\n",
    "    prefix = os.path.splitext(ibl_file)[0]\n",
    "    out_file = '{}.png'.format(prefix)\n",
    "    predict_fname = os.path.join(prediction_result_folder, out_file)\n",
    "    \n",
    "    ibl_img = np.array(Image.open(os.path.join(output_folder, ibl_file)))\n",
    "    shadow = predict(testing_img, np.array(ibl_img))\n",
    "    \n",
    "    ibl_img = ibl_img/np.max(ibl_img)\n",
    "    ibl_img = (ibl_img[:,:,0] + ibl_img[:,:,1] + ibl_img[:,:,2])/3.0\n",
    "    ibl_img = gaussian_filter(ibl_img, sigma=20)\n",
    "    show_np(ibl_img)\n",
    "    show_np(shadow)\n",
    "    \n",
    "    counter += 1\n",
    "    if counter > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make animations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 512/512 [00:16<00:00, 30.83it/s]\n",
      "100%|██████████| 512/512 [00:16<00:00, 30.32it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from valid_relight_ssn import render_animation\n",
    "\n",
    "# real_human = testing_img\n",
    "# show_np(real_human)\n",
    "# output_folder = 'results/animations/real_human'\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "# render_animation(testing_img, output_folder)\n",
    "\n",
    "training_human = '/home/ysheng/Dataset/soft_shadow/train/simulated_combine_female_long_fullbody_bridget8_wildwind_ssradclosedrobe_Base_Pose_Standing_A/imgs/0000000_mask.png'\n",
    "testing_img = np.array(Image.open(training_human))\n",
    "show_np(testing_img)\n",
    "output_folder = 'results/animations/training_human_own_light'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "render_animation(testing_img, output_folder)\n",
    "\n",
    "training_bottle = '/home/ysheng/Dataset/soft_shadow/train/bottle_0052_normalize/imgs/0000000_mask.png'\n",
    "testing_img = np.array(Image.open(training_bottle))\n",
    "show_np(testing_img)\n",
    "output_folder = 'results/animations/training_simple_obj'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "render_animation(testing_img, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import params\n",
    "\n",
    "parameters = params.params()\n",
    "parameters2 = params.params()\n",
    "print(parameters.get_trans_conv_step())\n",
    "\n",
    "parameters.set_trans_conv_step(2)\n",
    "print(parameters2.get_trans_conv_step())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

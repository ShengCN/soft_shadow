{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialize spent: 0.7725203037261963 ms\n",
      "Dataset initialize spent: 0.8047025203704834 ms\n",
      "training set size:  6027\n",
      "testing set size:  669\n",
      "num of keys: 6696\n",
      "num of one key:  12\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ssn_dataset\n",
    "from torchvision import transforms, utils\n",
    "import numpy as np\n",
    "\n",
    "csv_file = \"~/Dataset/soft_shadow/train/metadata.csv\"\n",
    "# compose_transform = None\n",
    "training_dataset = ssn_dataset.SSN_Dataset(csv_file, is_training = True)\n",
    "testing_dataset = ssn_dataset.SSN_Dataset(csv_file, is_training = False)\n",
    "\n",
    "print('training set size: ', len(training_dataset))\n",
    "print('testing set size: ',len(testing_dataset))\n",
    "\n",
    "keys = training_dataset.keys\n",
    "hash_map = training_dataset.hash\n",
    "print('num of keys:', len(keys))\n",
    "print('num of one key: ', len(hash_map[keys[0]]))\n",
    "\n",
    "# for j in range(10):\n",
    "#     for i in range(len(training_dataset)):\n",
    "#         data = training_dataset[i]\n",
    "# #         print(\"{} \\r\".format(i), flush=True, end=\"\")\n",
    "#         print(\"{} \".format(i))\n",
    "    \n",
    "# for i,data in enumerate(testing_dataset):\n",
    "#     print(\"{} \\r\".format(i), flush=True, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([36, 1, 256, 256])\n",
      "torch.Size([15, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.net_utils import show_batch, show_light_batch\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def vis_light(light_tensor):\n",
    "    channel = light_tensor.size()[0]\n",
    "    tensor_ret = torch.zeros(light_tensor.size())\n",
    "    for i in range(channel):\n",
    "        light_np = light_tensor[0].numpy()\n",
    "        print('max: ', np.max(light_np))\n",
    "        print('min: ', np.min(light_np))\n",
    "        # light_np = gaussian_filter(light_np * 100.0, sigma=3)/np.max(light_np)\n",
    "        tensor_ret[i] = torch.from_numpy(light_np) \n",
    "    return tensor_ret\n",
    "\n",
    "dataloader = DataLoader(training_dataset, batch_size=36, shuffle=False, num_workers=16)\n",
    "\n",
    "for i, (mask, light, shadow, nov_mask, nov_light, nov_shadow) in enumerate(dataloader):\n",
    "    print(mask.shape)\n",
    "    \n",
    "#     # concatenate human mask and shadow mask\n",
    "#     I_s = torch.cat((mask, shadow), dim=1)\n",
    "#     L_t = nov_light\n",
    "#     I_t = torch.cat((nov_mask, nov_shadow), dim=1)\n",
    "#     L_s = light\n",
    "#     # print('light size: ', light.size())\n",
    "#     show_batch(mask)\n",
    "#     show_batch(nov_mask)    \n",
    "#     show_batch(vis_light(light))    \n",
    "#     show_batch(vis_light(nov_light))\n",
    "#     show_batch(shadow)\n",
    "#     show_batch(nov_shadow)\n",
    "    \n",
    "#     break\n",
    "    \n",
    "#     human_gt = I_t[:,0,:,:]\n",
    "#     shadow_gt = I_t[:,1,:,:]\n",
    "    \n",
    "#     batch_size, c, h, w = I_t.size()\n",
    "#     human_mask, shadow_mask = torch.zeros(batch_size, h, w, dtype= torch.float32), torch.zeros(batch_size, h, w, dtype= torch.float32)\n",
    "#     human_mask[torch.where(human_gt !=0)] = 1\n",
    "#     shadow_mask[torch.where(shadow_gt !=0)] = 1\n",
    "    \n",
    "# #     print(human_mask.size())\n",
    "# #     print(shadow_mask.size())\n",
    "    \n",
    "#     show_batch(human_mask.view(batch_size, 1, h, w))\n",
    "#     show_batch(shadow_mask.view(batch_size, 1, h, w))\n",
    "    \n",
    "#     zero = torch.zeros(batch_size, h, w, dtype= torch.float32)\n",
    "    \n",
    "# #     print(human_gt.size())\n",
    "# #     print(torch.where(human_gt !=0)[0].size())\n",
    "# #     print(torch.where(human_gt ==0)[0].size())\n",
    "    \n",
    "#     weight = torch.where(human_gt ==0)[0].size()[0]/ float(torch.where(human_gt !=0)[0].size()[0]) \n",
    "#     pos_weight = torch.ones(human_mask.size())\n",
    "#     pos_weight[torch.where(human_gt !=0)] = weight\n",
    "    \n",
    "    \n",
    "    # print(criterion(zero, human_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn \n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "def to_numpy_img(t):\n",
    "    t_np = t.numpy()\n",
    "    t_np = np.transpose(t_np, (1,2,0))\n",
    "    return t_np\n",
    "\n",
    "test_tensor = torch.zeros(9,256, 256)\n",
    "test = to_numpy_img(test_tensor)\n",
    "test[128, 128, 0] = 1\n",
    "\n",
    "test_ = gaussian_filter(test, sigma = 10)\n",
    "seaborn.heatmap(test[:,:,0])\n",
    "seaborn.heatmap(test_[:,:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# todo, vectorize this process\n",
    "test_torch = torch.zeros(16,32)\n",
    "for h in range(test_torch.size()[0]):\n",
    "    test_torch[h,:] = abs(math.sin(h / 16.0 * 3.1415926)) + 0.001\n",
    "\n",
    "test_np = test_torch.detach().cpu().numpy()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(test_np,cmap='gray')light_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssn_submodule import Up\n",
    "import torch\n",
    "\n",
    "x1 = torch.randn(1,512, 16,16)\n",
    "x2 = torch.randn(1,256, 32,32)\n",
    "\n",
    "model = Up(512,256)\n",
    "out = model(x1,x2)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '/home/ysheng/Dataset/soft_shadow/single_human/notsimulated_combine_male_short_outfits_genesis8_armani_casualoutfit03_Base_Pose_Standing_A/ground_truth.txt'\n",
    "\n",
    "with open(data_file,'r') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "lines = [c.strip() for c in content]\n",
    "data_num = int(len(lines)/6)\n",
    "\n",
    "def get_pos(pos_str):\n",
    "    x = float(pos_str[1])\n",
    "    y = float(pos_str[2])\n",
    "    z = float(pos_str[3])\n",
    "    return np.array([x,y,z])\n",
    "\n",
    "def get_spherical(pos):\n",
    "    x,y,z = pos\n",
    "    alpha = np.arctan2(z,x)\n",
    "    beta = np.arctan2(y, np.sqrt(x**2 + z**2))\n",
    "    return alpha, beta\n",
    "\n",
    "prefix_list, alpha_list, beta_list = [], [], []\n",
    "for i in range(data_num):\n",
    "    prefix_str = lines[6 * i + 0]\n",
    "    human_pos_str = lines[6 * i + 3].split()\n",
    "    light_pos_str = lines[6 * i + 4].split()\n",
    "    human_pos = get_pos(human_pos_str)\n",
    "    light_pos = get_pos(light_pos_str)\n",
    "    \n",
    "    light_dir = light_pos - human_pos\n",
    "    light_dir_norm = light_dir/np.linalg.norm(light_dir, 2)\n",
    "    alpha, beta = get_spherical(light_dir_norm)\n",
    "    # print('alpha: {}, beta: {} \\n'.format(alpha, beta))\n",
    "    alpha_list.append(alpha + np.pi)\n",
    "    beta_list.append(beta + np.pi)    \n",
    "    prefix_list.append(prefix_str)\n",
    "    \n",
    "alpha_ary = np.array(alpha_list)\n",
    "beta_ary = np.array(beta_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def compute_IBL(alpha, beta):\n",
    "    h, w = 256, 256\n",
    "    IBL = np.zeros((h,w))\n",
    "    \n",
    "    two_pi = 2.0 * np.pi\n",
    "    alpha_coord, beta_coord = int(w * alpha/two_pi), int(h * beta/two_pi)\n",
    "    IBL[beta_coord, alpha_coord] = 1.0\n",
    "    return IBL\n",
    "\n",
    "def show_gau_light(ibl):\n",
    "    light_np = gaussian_filter(ibl, sigma=3)/np.max(ibl)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.imshow(light_np)\n",
    "\n",
    "for i in range(6400):\n",
    "    ibl = compute_IBL(alpha_ary[i], beta_ary[i])\n",
    "    show_gau_light(ibl)\n",
    "\n",
    "    light_img = '{}/{}_light.png'.format('/home/ysheng/Dataset/soft_shadow/single_human/notsimulated_combine_male_short_outfits_genesis8_armani_casualoutfit03_Base_Pose_Standing_A',prefix_list[i])\n",
    "    # light_img_np = np.array(Image.open(light_img).resize((32,32)))\n",
    "    light_img_np = np.array(Image.open(light_img))\n",
    "    show_gau_light(light_img_np)\n",
    "    \n",
    "    if i > 10:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
